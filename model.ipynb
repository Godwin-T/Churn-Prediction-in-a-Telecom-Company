{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import mlflow\n",
    "from hyperopt import hp, STATUS_OK, fmin, Trials, tpe\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import display\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/home/godwin/Documents/Workflow/Churn-Prediction-in-a-Telecom-Company/mlruns/1', creation_time=1687473013668, experiment_id='1', last_update_time=1687473013668, lifecycle_stage='active', name='Telcom Churn', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('sqlite:///mlflow.db')\n",
    "mlflow.set_experiment('Telcom Churn')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/Telco-Customer-Churn.csv'\n",
    "data = pd.read_csv(path)\n",
    "data.columns = data.columns.str.replace(' ', '_').str.lower()\n",
    "\n",
    "categorical_col = data.dtypes[data.dtypes == 'object'].index.tolist()\n",
    "for col in categorical_col:\n",
    "    data[col] = data[col].str.replace(' ', '_').str.lower()\n",
    "#data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerid</th>\n",
       "      <th>gender</th>\n",
       "      <th>seniorcitizen</th>\n",
       "      <th>partner</th>\n",
       "      <th>dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>phoneservice</th>\n",
       "      <th>multiplelines</th>\n",
       "      <th>internetservice</th>\n",
       "      <th>onlinesecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>deviceprotection</th>\n",
       "      <th>techsupport</th>\n",
       "      <th>streamingtv</th>\n",
       "      <th>streamingmovies</th>\n",
       "      <th>contract</th>\n",
       "      <th>paperlessbilling</th>\n",
       "      <th>paymentmethod</th>\n",
       "      <th>monthlycharges</th>\n",
       "      <th>totalcharges</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-vhveg</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no_phone_service</td>\n",
       "      <td>dsl</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic_check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-gnvde</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>34</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>dsl</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>one_year</td>\n",
       "      <td>no</td>\n",
       "      <td>mailed_check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.5</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-qpybk</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>dsl</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>mailed_check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-cfocw</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>45</td>\n",
       "      <td>no</td>\n",
       "      <td>no_phone_service</td>\n",
       "      <td>dsl</td>\n",
       "      <td>yes</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>one_year</td>\n",
       "      <td>no</td>\n",
       "      <td>bank_transfer_(automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-hqitu</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>fiber_optic</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>month-to-month</td>\n",
       "      <td>yes</td>\n",
       "      <td>electronic_check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerid  gender  seniorcitizen partner dependents  tenure phoneservice  \\\n",
       "0  7590-vhveg  female              0     yes         no       1           no   \n",
       "1  5575-gnvde    male              0      no         no      34          yes   \n",
       "2  3668-qpybk    male              0      no         no       2          yes   \n",
       "3  7795-cfocw    male              0      no         no      45           no   \n",
       "4  9237-hqitu  female              0      no         no       2          yes   \n",
       "\n",
       "      multiplelines internetservice onlinesecurity  ... deviceprotection  \\\n",
       "0  no_phone_service             dsl             no  ...               no   \n",
       "1                no             dsl            yes  ...              yes   \n",
       "2                no             dsl            yes  ...               no   \n",
       "3  no_phone_service             dsl            yes  ...              yes   \n",
       "4                no     fiber_optic             no  ...               no   \n",
       "\n",
       "  techsupport streamingtv streamingmovies        contract paperlessbilling  \\\n",
       "0          no          no              no  month-to-month              yes   \n",
       "1          no          no              no        one_year               no   \n",
       "2          no          no              no  month-to-month              yes   \n",
       "3         yes          no              no        one_year               no   \n",
       "4          no          no              no  month-to-month              yes   \n",
       "\n",
       "               paymentmethod monthlycharges  totalcharges churn  \n",
       "0           electronic_check          29.85         29.85    no  \n",
       "1               mailed_check          56.95        1889.5    no  \n",
       "2               mailed_check          53.85        108.15   yes  \n",
       "3  bank_transfer_(automatic)          42.30       1840.75    no  \n",
       "4           electronic_check          70.70        151.65   yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['churn'] = (data.churn=='yes').astype(int)\n",
    "categorical_col = data.dtypes[data.dtypes == 'object'].index.tolist()\n",
    "numerical_col = ['tenure', 'totalcharges', 'monthlycharges']\n",
    "\n",
    "categorical_col.remove('customerid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25,\n",
    "                                         random_state=0)\n",
    "\n",
    "train_x = train_data.drop(['churn'], axis = 1)\n",
    "test_x = test_data.drop(['churn'], axis = 1)\n",
    "\n",
    "train_y = train_data.pop('churn')\n",
    "test_y = test_data.pop('churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse = False)\n",
    "dv.fit(train_x[categorical_col + numerical_col].to_dict(orient = 'records'))\n",
    "\n",
    "train_x = dv.transform(train_x[categorical_col + numerical_col].to_dict(orient = 'records'))\n",
    "test_x = dv.transform(test_x[categorical_col + numerical_col].to_dict(orient = 'records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred, data_category):\n",
    "\n",
    "    accuracy_ = accuracy_score(y_true, y_pred)\n",
    "    precision_ = precision_score(y_true, y_pred)\n",
    "    recall_ = recall_score(y_true, y_pred)\n",
    "    f1score_ = f1_score(y_true, y_pred)\n",
    "\n",
    "    if data_category == 'train':\n",
    "\n",
    "        out = {\"Train accuracy Score\" : accuracy_, \n",
    "            \"Train precision Score\" :precision_, \n",
    "            \"Train recall Score\" : recall_, \n",
    "            \"Train f1 Score\" : f1score_}\n",
    "    else:\n",
    "        out = {\"Test accuracy Score\" : accuracy_, \n",
    "            \"Test precision Score\" :precision_, \n",
    "            \"Test recall Score\" : recall_, \n",
    "            \"Test f1 Score\" : f1score_}\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_model(c_values = range(1, 101, 10), model_tag = None):\n",
    "\n",
    "    for c_value in c_values:\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            \n",
    "            mlflow.set_tag('Developer', 'Godwin')\n",
    "            mlflow.set_tag('Model Type', model_tag)\n",
    "            mlflow.set_tag('Model Name', 'Logistic Regression')\n",
    "            mlflow.log_param('C Value', c_value)\n",
    "\n",
    "            model = LogisticRegression(C = c_value)\n",
    "            model.fit(train_x, train_y)\n",
    "\n",
    "            train_pred = model.predict(train_x)\n",
    "            train_output_eval = evaluation(train_y, train_pred, 'train')\n",
    "            test_pred = model.predict(test_x)\n",
    "            test_output_eval = evaluation(test_y, test_pred, 'test')   \n",
    "            data.to_csv('new_data.csv', header=False)    \n",
    "            \n",
    "            mlflow.log_metrics(train_output_eval)\n",
    "            mlflow.log_metrics(test_output_eval)\n",
    "            mlflow.log_artifact('new_data.csv', 'data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_tree_objective(params):\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('Model Type', 'Base Model')\n",
    "        mlflow.set_tag(\"model\", \"Decision Tree\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        model = DecisionTreeClassifier(**params)\n",
    "        model.fit(train_x, train_y)\n",
    "        train_pred = model.predict(train_x)\n",
    "        train_output_eval = evaluation(train_y, train_pred, 'train')\n",
    "        test_pred = model.predict(test_x)\n",
    "        test_output_eval = evaluation(test_y, test_pred, 'test')   \n",
    "        data.to_csv('new_data.csv', header=False)    \n",
    "        mlflow.log_metrics(train_output_eval)\n",
    "        mlflow.log_metrics(test_output_eval)\n",
    "        mlflow.log_artifact('new_data.csv', 'data.csv')\n",
    "\n",
    "    return {\"loss\": test_output_eval['Test accuracy Score'], 'status': STATUS_OK}\n",
    "\n",
    "def random_forest_objective(params):\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('Model Type', 'Base Model')\n",
    "        mlflow.set_tag(\"model\", \"Random Forest\")\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        model = RandomForestClassifier(**params)\n",
    "        model.fit(train_x, train_y)\n",
    "        train_pred = model.predict(train_x)\n",
    "        train_output_eval = evaluation(train_y, train_pred, 'train')\n",
    "        test_pred = model.predict(test_x)\n",
    "        test_output_eval = evaluation(test_y, test_pred, 'test')   \n",
    "        data.to_csv('new_data.csv', header=False)    \n",
    "        mlflow.log_metrics(train_output_eval)\n",
    "        mlflow.log_metrics(test_output_eval)\n",
    "        mlflow.log_artifact('new_data.csv', 'data.csv')\n",
    "\n",
    "    return {\"loss\": test_output_eval['Test accuracy Score'], 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def single_tree():\n",
    "\n",
    "    space = {\n",
    "    \"max_depth\": hp.randint(\"max_depth\", 1, 15),\n",
    "    'min_samples_split': hp.randint(\"min_samples_split\", 2, 15),\n",
    "    'min_samples_leaf': hp.randint(\"min_samples_leaf\", 1, 15),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "    fn= single_tree_objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    "    )\n",
    "    return best_result\n",
    "\n",
    "def random_forest(): \n",
    "\n",
    "    space = {\n",
    "    \"n_estimators\": hp.choice(\"n_estimators\", [100, 200, 300, 400,500,600]),\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "    'min_samples_split': hp.randint(\"min_samples_split\", 2, 15),\n",
    "    'min_samples_leaf': hp.randint(\"min_samples_leaf\", 1, 15),\n",
    "    \"criterion\": hp.choice(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "    fn=random_forest_objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,\n",
    "    trials=Trials()\n",
    "    )\n",
    "    return best_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = xgb.DMatrix(train_x, label=train_y)\n",
    "valid = xgb.DMatrix(test_x, label=test_y)\n",
    "def xgboost_objective(params):\n",
    "    with mlflow.start_run():\n",
    "\n",
    "        mlflow.set_tag('Developer', 'Godwin')\n",
    "        mlflow.set_tag('Model Type', 'Base Model')\n",
    "        mlflow.set_tag(\"model\", \"Xgboost\")\n",
    "        mlflow.log_params(params)\n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(valid, 'validation')],\n",
    "            early_stopping_rounds=50\n",
    "        )\n",
    "        train_pred = model.predict(train)\n",
    "        train_output_eval = evaluation(train_y, train_pred, 'train')\n",
    "        test_pred = model.predict(valid)\n",
    "        test_output_eval = evaluation(test_y, test_pred, 'test')   \n",
    "        data.to_csv('new_data.csv', header=False)    \n",
    "        mlflow.log_metrics(train_output_eval)\n",
    "        mlflow.log_metrics(test_output_eval)\n",
    "        mlflow.log_artifact('new_data.csv', 'data.csv')\n",
    "    return {'loss': test_output_eval['Test accuracy Score'], 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "def xgboost_dev():\n",
    "\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 4, 100, 1)),\n",
    "        'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', -5, -1),\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', -6, -1),\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', -1, 3),\n",
    "        'objective': 'binary:logistic',\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    best_result = fmin(\n",
    "        fn= xgboost_objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=50,\n",
    "        trials=Trials()\n",
    "    )\n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:59<00:00,  1.19s/trial, best loss: 0.7370812038614424]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 0, 'max_depth': 1, 'min_samples_leaf': 8, 'min_samples_split': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [04:18<00:00,  5.17s/trial, best loss: 0.7370812038614424]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 1,\n",
       " 'max_depth': 65.0,\n",
       " 'min_samples_leaf': 7,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 3}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation-logloss:0.65273                        \n",
      "[1]\tvalidation-logloss:0.61922                        \n",
      "[2]\tvalidation-logloss:0.59169                        \n",
      "[3]\tvalidation-logloss:0.56816                        \n",
      "[4]\tvalidation-logloss:0.54839                        \n",
      "[5]\tvalidation-logloss:0.53190                        \n",
      "[6]\tvalidation-logloss:0.51766                        \n",
      "[7]\tvalidation-logloss:0.50551                        \n",
      "[8]\tvalidation-logloss:0.49503                        \n",
      "[9]\tvalidation-logloss:0.48650                        \n",
      "[10]\tvalidation-logloss:0.47842                       \n",
      "[11]\tvalidation-logloss:0.47223                       \n",
      "[12]\tvalidation-logloss:0.46715                       \n",
      "[13]\tvalidation-logloss:0.46259                       \n",
      "[14]\tvalidation-logloss:0.45916                       \n",
      "[15]\tvalidation-logloss:0.45631                       \n",
      "[16]\tvalidation-logloss:0.45293                       \n",
      "[17]\tvalidation-logloss:0.45112                       \n",
      "[18]\tvalidation-logloss:0.44936                       \n",
      "[19]\tvalidation-logloss:0.44698                       \n",
      "[20]\tvalidation-logloss:0.44620                       \n",
      "[21]\tvalidation-logloss:0.44488                       \n",
      "[22]\tvalidation-logloss:0.44460                       \n",
      "[23]\tvalidation-logloss:0.44381                       \n",
      "[24]\tvalidation-logloss:0.44413                       \n",
      "[25]\tvalidation-logloss:0.44361                       \n",
      "[26]\tvalidation-logloss:0.44427                       \n",
      "[27]\tvalidation-logloss:0.44323                       \n",
      "[28]\tvalidation-logloss:0.44339                       \n",
      "[29]\tvalidation-logloss:0.44373                       \n",
      "[30]\tvalidation-logloss:0.44374                       \n",
      "[31]\tvalidation-logloss:0.44436                       \n",
      "[32]\tvalidation-logloss:0.44496                       \n",
      "[33]\tvalidation-logloss:0.44431                       \n",
      "[34]\tvalidation-logloss:0.44463                       \n",
      "[35]\tvalidation-logloss:0.44533                       \n",
      "[36]\tvalidation-logloss:0.44658                       \n",
      "[37]\tvalidation-logloss:0.44709                       \n",
      "[38]\tvalidation-logloss:0.44756                       \n",
      "[39]\tvalidation-logloss:0.44874                       \n",
      "[40]\tvalidation-logloss:0.44917                       \n",
      "[41]\tvalidation-logloss:0.44955                       \n",
      "[42]\tvalidation-logloss:0.44986                       \n",
      "[43]\tvalidation-logloss:0.45049                       \n",
      "[44]\tvalidation-logloss:0.45070                       \n",
      "[45]\tvalidation-logloss:0.45155                       \n",
      "[46]\tvalidation-logloss:0.45205                       \n",
      "[47]\tvalidation-logloss:0.45239                       \n",
      "[48]\tvalidation-logloss:0.45252                       \n",
      "[49]\tvalidation-logloss:0.45338                       \n",
      "[50]\tvalidation-logloss:0.45373                       \n",
      "[51]\tvalidation-logloss:0.45458                       \n",
      "[52]\tvalidation-logloss:0.45516                       \n",
      "[53]\tvalidation-logloss:0.45617                       \n",
      "[54]\tvalidation-logloss:0.45737                       \n",
      "[55]\tvalidation-logloss:0.45858                       \n",
      "[56]\tvalidation-logloss:0.45961                       \n",
      "[57]\tvalidation-logloss:0.46049                       \n",
      "[58]\tvalidation-logloss:0.46117                       \n",
      "[59]\tvalidation-logloss:0.46260                       \n",
      "[60]\tvalidation-logloss:0.46342                       \n",
      "[61]\tvalidation-logloss:0.46428                       \n",
      "[62]\tvalidation-logloss:0.46460                       \n",
      "[63]\tvalidation-logloss:0.46469                       \n",
      "[64]\tvalidation-logloss:0.46505                       \n",
      "[65]\tvalidation-logloss:0.46507                       \n",
      "[66]\tvalidation-logloss:0.46573                       \n",
      "[67]\tvalidation-logloss:0.46627                       \n",
      "[68]\tvalidation-logloss:0.46729                       \n",
      "[69]\tvalidation-logloss:0.46773                       \n",
      "[70]\tvalidation-logloss:0.46828                       \n",
      "[71]\tvalidation-logloss:0.46949                       \n",
      "[72]\tvalidation-logloss:0.47020                       \n",
      "[73]\tvalidation-logloss:0.47148                       \n",
      "[74]\tvalidation-logloss:0.47258                       \n",
      "[75]\tvalidation-logloss:0.47343                       \n",
      "[76]\tvalidation-logloss:0.47350                       \n",
      "  0%|          | 0/50 [01:41<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR [hyperopt.fmin] job exception: Classification metrics can't handle a mix of binary and continuous targets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:43<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m xgboost_dev()\n",
      "Cell \u001b[0;32mIn[16], line 40\u001b[0m, in \u001b[0;36mxgboost_dev\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mxgboost_dev\u001b[39m():\n\u001b[1;32m     30\u001b[0m     search_space \u001b[39m=\u001b[39m {\n\u001b[1;32m     31\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m: scope\u001b[39m.\u001b[39mint(hp\u001b[39m.\u001b[39mquniform(\u001b[39m'\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m1\u001b[39m)),\n\u001b[1;32m     32\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m: hp\u001b[39m.\u001b[39mloguniform(\u001b[39m'\u001b[39m\u001b[39mlearning_rate\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m3\u001b[39m, \u001b[39m0\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m42\u001b[39m\n\u001b[1;32m     38\u001b[0m     }\n\u001b[0;32m---> 40\u001b[0m     best_result \u001b[39m=\u001b[39m fmin(\n\u001b[1;32m     41\u001b[0m         fn\u001b[39m=\u001b[39;49m xgboost_objective,\n\u001b[1;32m     42\u001b[0m         space\u001b[39m=\u001b[39;49msearch_space,\n\u001b[1;32m     43\u001b[0m         algo\u001b[39m=\u001b[39;49mtpe\u001b[39m.\u001b[39;49msuggest,\n\u001b[1;32m     44\u001b[0m         max_evals\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     45\u001b[0m         trials\u001b[39m=\u001b[39;49mTrials()\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m best_result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hyperopt/fmin.py:540\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    537\u001b[0m     fn \u001b[39m=\u001b[39m __objective_fmin_wrapper(fn)\n\u001b[1;32m    539\u001b[0m \u001b[39mif\u001b[39;00m allow_trials_fmin \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(trials, \u001b[39m\"\u001b[39m\u001b[39mfmin\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     \u001b[39mreturn\u001b[39;00m trials\u001b[39m.\u001b[39;49mfmin(\n\u001b[1;32m    541\u001b[0m         fn,\n\u001b[1;32m    542\u001b[0m         space,\n\u001b[1;32m    543\u001b[0m         algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    544\u001b[0m         max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    545\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    546\u001b[0m         loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    547\u001b[0m         max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    548\u001b[0m         rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    549\u001b[0m         pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    550\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    551\u001b[0m         catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    552\u001b[0m         return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    553\u001b[0m         show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    554\u001b[0m         early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    555\u001b[0m         trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    556\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[39mif\u001b[39;00m trials \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    559\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(trials_save_file):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hyperopt/base.py:671\u001b[0m, in \u001b[0;36mTrials.fmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[39m# -- Stop-gap implementation!\u001b[39;00m\n\u001b[1;32m    667\u001b[0m \u001b[39m#    fmin should have been a Trials method in the first place\u001b[39;00m\n\u001b[1;32m    668\u001b[0m \u001b[39m#    but for now it's still sitting in another file.\u001b[39;00m\n\u001b[1;32m    669\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfmin\u001b[39;00m \u001b[39mimport\u001b[39;00m fmin\n\u001b[0;32m--> 671\u001b[0m \u001b[39mreturn\u001b[39;00m fmin(\n\u001b[1;32m    672\u001b[0m     fn,\n\u001b[1;32m    673\u001b[0m     space,\n\u001b[1;32m    674\u001b[0m     algo\u001b[39m=\u001b[39;49malgo,\n\u001b[1;32m    675\u001b[0m     max_evals\u001b[39m=\u001b[39;49mmax_evals,\n\u001b[1;32m    676\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    677\u001b[0m     loss_threshold\u001b[39m=\u001b[39;49mloss_threshold,\n\u001b[1;32m    678\u001b[0m     trials\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m    679\u001b[0m     rstate\u001b[39m=\u001b[39;49mrstate,\n\u001b[1;32m    680\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    681\u001b[0m     max_queue_len\u001b[39m=\u001b[39;49mmax_queue_len,\n\u001b[1;32m    682\u001b[0m     allow_trials_fmin\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# -- prevent recursion\u001b[39;49;00m\n\u001b[1;32m    683\u001b[0m     pass_expr_memo_ctrl\u001b[39m=\u001b[39;49mpass_expr_memo_ctrl,\n\u001b[1;32m    684\u001b[0m     catch_eval_exceptions\u001b[39m=\u001b[39;49mcatch_eval_exceptions,\n\u001b[1;32m    685\u001b[0m     return_argmin\u001b[39m=\u001b[39;49mreturn_argmin,\n\u001b[1;32m    686\u001b[0m     show_progressbar\u001b[39m=\u001b[39;49mshow_progressbar,\n\u001b[1;32m    687\u001b[0m     early_stop_fn\u001b[39m=\u001b[39;49mearly_stop_fn,\n\u001b[1;32m    688\u001b[0m     trials_save_file\u001b[39m=\u001b[39;49mtrials_save_file,\n\u001b[1;32m    689\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hyperopt/fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    583\u001b[0m rval\u001b[39m.\u001b[39mcatch_eval_exceptions \u001b[39m=\u001b[39m catch_eval_exceptions\n\u001b[1;32m    585\u001b[0m \u001b[39m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[0;32m--> 586\u001b[0m rval\u001b[39m.\u001b[39;49mexhaust()\n\u001b[1;32m    588\u001b[0m \u001b[39mif\u001b[39;00m return_argmin:\n\u001b[1;32m    589\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(trials\u001b[39m.\u001b[39mtrials) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hyperopt/fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexhaust\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    363\u001b[0m     n_done \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials)\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_evals \u001b[39m-\u001b[39;49m n_done, block_until_done\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49masynchronous)\n\u001b[1;32m    365\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hyperopt/fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    297\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoll_interval_secs)\n\u001b[1;32m    298\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mserial_evaluate()\n\u001b[1;32m    302\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials\u001b[39m.\u001b[39mrefresh()\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials_save_file \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hyperopt/fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m ctrl \u001b[39m=\u001b[39m base\u001b[39m.\u001b[39mCtrl(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrials, current_trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdomain\u001b[39m.\u001b[39;49mevaluate(spec, ctrl)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     logger\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mjob exception: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m \u001b[39mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/hyperopt/base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    884\u001b[0m     \u001b[39m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[1;32m    885\u001b[0m     \u001b[39m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[1;32m    886\u001b[0m     \u001b[39m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     pyll_rval \u001b[39m=\u001b[39m pyll\u001b[39m.\u001b[39mrec_eval(\n\u001b[1;32m    888\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpr,\n\u001b[1;32m    889\u001b[0m         memo\u001b[39m=\u001b[39mmemo,\n\u001b[1;32m    890\u001b[0m         print_node_on_error\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[1;32m    891\u001b[0m     )\n\u001b[0;32m--> 892\u001b[0m     rval \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(pyll_rval)\n\u001b[1;32m    894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(rval, (\u001b[39mfloat\u001b[39m, \u001b[39mint\u001b[39m, np\u001b[39m.\u001b[39mnumber)):\n\u001b[1;32m    895\u001b[0m     dict_rval \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mfloat\u001b[39m(rval), \u001b[39m\"\u001b[39m\u001b[39mstatus\u001b[39m\u001b[39m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[0;32mIn[16], line 18\u001b[0m, in \u001b[0;36mxgboost_objective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     10\u001b[0m model \u001b[39m=\u001b[39m xgb\u001b[39m.\u001b[39mtrain(\n\u001b[1;32m     11\u001b[0m     params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m     12\u001b[0m     dtrain\u001b[39m=\u001b[39mtrain,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     early_stopping_rounds\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     17\u001b[0m train_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(train)\n\u001b[0;32m---> 18\u001b[0m train_output_eval \u001b[39m=\u001b[39m evaluation(train_y, train_pred, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m test_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(valid)\n\u001b[1;32m     20\u001b[0m test_output_eval \u001b[39m=\u001b[39m evaluation(test_y, test_pred, \u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m)   \n",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m, in \u001b[0;36mevaluation\u001b[0;34m(y_true, y_pred, data_category)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluation\u001b[39m(y_true, y_pred, data_category):\n\u001b[0;32m----> 5\u001b[0m     accuracy_ \u001b[39m=\u001b[39m accuracy_score(y_true, y_pred)\n\u001b[1;32m      6\u001b[0m     precision_ \u001b[39m=\u001b[39m precision_score(y_true, y_pred)\n\u001b[1;32m      7\u001b[0m     recall_ \u001b[39m=\u001b[39m recall_score(y_true, y_pred)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[1;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[1;32m    189\u001b[0m )\n\u001b[1;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    202\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \n\u001b[1;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:95\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     92\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     96\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     97\u001b[0m             type_true, type_pred\n\u001b[1;32m     98\u001b[0m         )\n\u001b[1;32m     99\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    102\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "xgboost_dev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric(actual, predicted, t):\n",
    "\n",
    "    accuracy = (predicted == actual).mean()\n",
    "    actual_positive = (actual == 1)\n",
    "    actual_negative = (actual == 0)\n",
    "\n",
    "    predicted_positive = (predicted >= t)\n",
    "    predicted_negative = (predicted < t)\n",
    "\n",
    "\n",
    "\n",
    "    tp = (actual_positive & predicted_positive).sum()\n",
    "    tn = (actual_negative & predicted_negative).sum()\n",
    "    fp = (actual_negative & predicted_positive).sum()\n",
    "    fn = (actual_positive & predicted_negative).sum()\n",
    "\n",
    "    tpr = tp/ (tp + fn)\n",
    "    fpr = fp/ (fp + tn)\n",
    "\n",
    "    precision = tp/(tp + fp)\n",
    "    recall = tp/(tp +fn)\n",
    "    f1_score = 2 * ((precision * recall)/ (precision + recall))\n",
    "\n",
    "    return tn, fp, fn, tp, precision, recall, tpr, fpr, f1_score#, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_rates(y_test, prediction):\n",
    "\n",
    "    actual_positive = (y_test == 1)\n",
    "    actual_negative = (y_test == 0)\n",
    "\n",
    "    predicted_positive = (prediction >= t)\n",
    "    predicted_negative = (prediction < t)\n",
    "\n",
    "    true_positive = (actual_positive & predicted_positive).sum()\n",
    "    true_negative = (actual_negative & predicted_negative).sum()\n",
    "    false_positive = (actual_negative & predicted_positive).sum()\n",
    "    false_negative = (actual_positive & predicted_negative).sum()\n",
    "\n",
    "    score.append((t,true_positive, false_positive, false_negative, true_negative))\n",
    "\n",
    "    df = pd.DataFrame(score, columns= ['threshold','true_positive', 'false_positive', 'false_negative', 'true_negative'])\n",
    "    df.true_positive_rate = df.true_positive/(df.true_positive + df.false_negative)\n",
    "    df.false_positive_rate = df.false_positive/(df.true_negative + df.false_positive)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse = False)\n",
    "def train(data, y, c):\n",
    "    dv.fit(data[categorical_col + numerical_col].to_dict(orient = 'records'))\n",
    "    X_train = dv.transform(data[categorical_col + numerical_col].to_dict(orient = 'records'))\n",
    "\n",
    "    model = LogisticRegression(C = c, max_iter = 1000)\n",
    "    model.fit(X_train, y)\n",
    "    return dv, model\n",
    "\n",
    "def predict(data, dv, model):\n",
    "    X_test = dv.transform(data[categorical_col + numerical_col].to_dict(orient = 'records'))\n",
    "    prediction = model.predict_proba(X_test)[:,1]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dv, model = train(train_data, y_train, c = 1)\n",
    "prediction = predict(test_data, dv, model)\n",
    "\n",
    "tn, fp, fn, tp, precision, recall, tpr, fpr, f1_score = metric(y_test, prediction, 0.5)\n",
    "cm = np.array([[tn, fp], [fn, tp]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8581973739803048"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "out = 'Churn.bin'\n",
    "\n",
    "with open(out, 'wb') as f:\n",
    "    pickle.dump((dv,model), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(out, 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data.iloc[8].to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a2031be23302a6f80daad80b84b83a86f535e1c11907b65b4c4b25f3c409004f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
